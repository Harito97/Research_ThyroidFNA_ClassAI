{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to_ann_39 & to_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Đọc CSV\n",
    "df = pd.read_csv('/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/train_not_aug.csv')\n",
    "\n",
    "# Hàm chuyển predicted_vector từ string thành list\n",
    "def to_ann_39(vec_str):\n",
    "    return np.array(ast.literal_eval(vec_str)).flatten()\n",
    "\n",
    "def to_transformer(vec_str):\n",
    "    return np.array(ast.literal_eval(vec_str))\n",
    "\n",
    "# Áp dụng hàm cho từng bản ghi để chuyển đổi predicted_vector từ string thành numpy array\n",
    "df['to_ann_39'] = df['predicted_vector'].apply(to_ann_39)\n",
    "df['to_transformer'] = df['predicted_vector'].apply(to_transformer)\n",
    "\n",
    "# type(df['to_ann_39'][0])      # numpy.ndarray\n",
    "# df['to_ann_39'][0].shape      # (39,)\n",
    "\n",
    "# type(df['to_transformer'][0])   # numpy.ndarray\n",
    "# df['to_transformer'][0].shape   # (13, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize dữ liệu\n",
    "X = np.vstack(df['to_ann_39'].values)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Sử dụng PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Tính variance explained ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Elbow Method\n",
    "plt.plot(range(1, len(explained_variance)+1), np.cumsum(explained_variance), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Sử dụng PCA giữ lại 95% thông tin\n",
    "pca_95 = PCA(0.95)\n",
    "X_pca_95 = pca_95.fit_transform(X_scaled)\n",
    "\n",
    "# In ra số chiều sau khi giảm\n",
    "print(f'Số chiều sau khi giảm: {X_pca_95.shape[1]}')\n",
    "\n",
    "# Lưu kết quả PCA vào cột mới trong DataFrame\n",
    "df['pca95_to_ann'] = list(X_pca_95)\n",
    "\n",
    "# Lưu cấu trúc PCA để áp dụng cho tập val và test\n",
    "with open('pca_95.pkl', 'wb') as f:\n",
    "    pickle.dump(pca_95, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn số chiều phù hợp từ Elbow Method\n",
    "n_components_optimal = np.argmax(np.cumsum(explained_variance) >= 0.90) + 1  # Ví dụ chọn số chiều khi explained variance đạt 90%\n",
    "\n",
    "print(f'Số chiều tối ưu: {n_components_optimal}')\n",
    "\n",
    "# Sử dụng PCA với số chiều từ Elbow Method\n",
    "pca_elbow = PCA(n_components=n_components_optimal)\n",
    "X_pca_elbow = pca_elbow.fit_transform(X_scaled)\n",
    "\n",
    "# Lưu kết quả PCA từ Elbow Method vào cột mới\n",
    "df['pcaelbow_to_ann'] = list(X_pca_elbow)\n",
    "\n",
    "# Lưu cấu trúc PCA từ Elbow Method để áp dụng cho tập val và test\n",
    "with open('pca_elbow.pkl', 'wb') as f:\n",
    "    pickle.dump(pca_elbow, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sử dụng PLSRegression để giảm chiều về 2\n",
    "pls = PLSRegression(n_components=2)\n",
    "X_pls = pls.fit_transform(X_scaled, df['label'])[0]\n",
    "\n",
    "# Lưu kết quả PLS vào DataFrame\n",
    "df['pls_to_ann'] = list(X_pls)\n",
    "\n",
    "# Trực quan hóa dữ liệu sau khi giảm chiều\n",
    "# Định nghĩa colormap cho 3 nhãn\n",
    "cmap = ListedColormap(['r', 'g', 'b'])  # Đỏ cho nhãn 0, xanh lá cho nhãn 1, xanh dương cho nhãn 2\n",
    "\n",
    "# Trực quan hóa dữ liệu sau khi giảm chiều\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pls[:, 0], X_pls[:, 1], c=df['label'], cmap=cmap, edgecolor='k')\n",
    "\n",
    "# Gắn nhãn cho trục và tiêu đề\n",
    "plt.xlabel('PLS Component 1')\n",
    "plt.ylabel('PLS Component 2')\n",
    "plt.title('PLS Reduced Data Visualization')\n",
    "\n",
    "# Tạo colorbar với các nhãn\n",
    "cbar = plt.colorbar(scatter, ticks=[0, 1, 2])\n",
    "cbar.set_label('Label')\n",
    "cbar.set_ticks([0, 1, 2])  # Thiết lập chính xác 3 giá trị nhãn\n",
    "cbar.set_ticklabels(['Class 0', 'Class 1', 'Class 2'])\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['path_to_image', 'predicted_vector', 'predicted_label'], inplace=True)\n",
    "df.head()\n",
    "\n",
    "# Sau khi có thêm PLS, lưu lại DataFrame thành CSV\n",
    "df.to_csv('train_set_processed_data_with_pca_pls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for val & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/val_not_aug.csv')\n",
    "df_test = pd.read_csv('/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/test_not_aug.csv')\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lại PCA đã lưu\n",
    "with open('pca_95.pkl', 'rb') as f:\n",
    "    pca_95_loaded = pickle.load(f)\n",
    "\n",
    "with open('pca_elbow.pkl', 'rb') as f:\n",
    "    pca_elbow_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More work to do here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Đọc dữ liệu từ train set\n",
    "df_train = pd.read_csv(\"/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/train_not_aug.csv\")\n",
    "df_val = pd.read_csv(\"/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/val_not_aug.csv\")\n",
    "df_test = pd.read_csv(\"/mnt/DataSamsung/project/Research_ThyroidFNA_ClassAI/phase3_140924/data/temp/test_not_aug.csv\")\n",
    "\n",
    "# Chuyển đổi mỗi chuỗi thành mảng numpy\n",
    "df_train['predicted_vector'] = df_train['predicted_vector'].apply(lambda x: np.array(eval(x)))\n",
    "df_val['predicted_vector'] = df_val['predicted_vector'].apply(lambda x: np.array(eval(x)))\n",
    "df_test['predicted_vector'] = df_test['predicted_vector'].apply(lambda x: np.array(eval(x)))\n",
    "\n",
    "# Scale dữ liệu trước khi áp dụng PCA/PLS\n",
    "X_train_scaled = df_train['predicted_vector']\n",
    "X_val_scaled = df_val['predicted_vector']\n",
    "X_test_scaled = df_test['predicted_vector']\n",
    "\n",
    "# PCA giữ 95% thông tin\n",
    "pca_95 = PCA(0.99)  # n_components=0.95\n",
    "X_train_pca95 = pca_95.fit_transform(X_train_scaled)\n",
    "X_val_pca95 = pca_95.transform(X_val_scaled)\n",
    "X_test_pca95 = pca_95.transform(X_test_scaled)\n",
    "\n",
    "# Lưu PCA 95 để sử dụng sau này\n",
    "joblib.dump(pca_95, './pca_95.pkl')\n",
    "\n",
    "# Lưu lại PCA này và thêm vào df_train, df_val, df_test\n",
    "df_train['pca95_to_ann'] = X_train_pca95.tolist()\n",
    "df_val['pca95_to_ann'] = X_val_pca95.tolist()\n",
    "df_test['pca95_to_ann'] = X_test_pca95.tolist()\n",
    "\n",
    "# PCA bằng elbow method\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "# Tính variance explained ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "# Elbow Method\n",
    "plt.plot(range(1, len(explained_variance)+1), np.cumsum(explained_variance), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_elbow = PCA(n_components=5)  # Chọn số chiều từ elbow method đã xác định trước\n",
    "X_train_pca_elbow = pca_elbow.fit_transform(X_train_scaled)\n",
    "X_val_pca_elbow = pca_elbow.transform(X_val_scaled)\n",
    "X_test_pca_elbow = pca_elbow.transform(X_test_scaled)\n",
    "\n",
    "# Lưu PCA elbow để sử dụng sau này\n",
    "joblib.dump(pca_elbow, './pca_elbow.pkl')\n",
    "\n",
    "# Lưu lại PCA này và thêm vào df_train, df_val, df_test\n",
    "df_train['pcaelbow_to_ann'] = X_train_pca_elbow.tolist()\n",
    "df_val['pcaelbow_to_ann'] = X_val_pca_elbow.tolist()\n",
    "df_test['pcaelbow_to_ann'] = X_test_pca_elbow.tolist()\n",
    "\n",
    "# PLS Regression để giảm về 2 chiều\n",
    "pls = PLSRegression(n_components=2)\n",
    "X_train_pls = pls.fit_transform(X_train_scaled, df_train['label'])[0]\n",
    "X_val_pls = pls.transform(X_val_scaled)\n",
    "X_test_pls = pls.transform(X_test_scaled)\n",
    "\n",
    "# Lưu PLS model để sử dụng sau này\n",
    "joblib.dump(pls, './pls_model.pkl')\n",
    "\n",
    "# Trực quan hóa tập train sau khi PLS\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train_pls[:, 0], X_train_pls[:, 1], c=df_train['label'], cmap='viridis', edgecolor='k')\n",
    "plt.xlabel('PLS Component 1')\n",
    "plt.ylabel('PLS Component 2')\n",
    "plt.title('PLS Reduced Data Visualization (Train Set)')\n",
    "# Thêm thanh màu (colorbar) và đảm bảo rằng chỉ có 3 nhãn (0, 1, 2)\n",
    "cbar = plt.colorbar(scatter, ticks=[0, 1, 2])\n",
    "cbar.set_label('Label')\n",
    "plt.show()\n",
    "\n",
    "# Lưu lại kết quả PLS vào dataframe\n",
    "df_train['pls_to_ann'] = X_train_pls.tolist()\n",
    "df_val['pls_to_ann'] = X_val_pls.tolist()\n",
    "df_test['pls_to_ann'] = X_test_pls.tolist()\n",
    "\n",
    "# Lưu file CSV cho train, val và test\n",
    "df_train.to_csv(\"./train_set_with_pca_pls.csv\", index=False)\n",
    "df_val.to_csv(\"./val_set_with_pca_pls.csv\", index=False)\n",
    "df_test.to_csv(\"./test_set_with_pca_pls.csv\", index=False)\n",
    "\n",
    "# Load lại dữ liệu để chuẩn bị cho deep learning\n",
    "df_train = pd.read_csv(\"./train_set_with_pca_pls.csv\")\n",
    "df_val = pd.read_csv(\"./val_set_with_pca_pls.csv\")\n",
    "df_test = pd.read_csv(\"./test_set_with_pca_pls.csv\")\n",
    "\n",
    "# Lựa chọn các trường để train mạng deep learning\n",
    "X_train = df_train['pca95_to_ann'].apply(eval).tolist()\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "X_val = df_val['pca95_to_ann'].apply(eval).tolist()\n",
    "y_val = df_val['label'].values\n",
    "\n",
    "X_test = df_test['pca95_to_ann'].apply(eval).tolist()\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "# Bây giờ bạn có thể sử dụng X_train, y_train, X_val, y_val, X_test, y_test để train mô hình deep learning\n",
    "\n",
    "# Load lại mô hình PCA/PLS đã lưu để sử dụng tiếp\n",
    "scaler = joblib.load('./scaler.pkl')\n",
    "pca_95 = joblib.load('./pca_95.pkl')\n",
    "pca_elbow = joblib.load('./pca_elbow.pkl')\n",
    "pls = joblib.load('./pls_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_work#311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
