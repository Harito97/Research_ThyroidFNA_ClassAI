{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for ANN  \n",
    "\n",
    "X shape will be (-1, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def load_data(csv_path):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     # Convert the string of predicted_vector to a proper list of floats\n",
    "#     df[\"predicted_vector\"] = df[\"predicted_vector\"].apply(lambda x: eval(x))\n",
    "#     df.drop([\"path_to_image\", \"predicted_label\"], axis=1, inplace=True)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def create_data_train_ANN(df, file_name_save):\n",
    "#     # X = np.array([np.array(x).flatten() for x in test_df['predicted_vector']])\n",
    "#     # y = df[\"true_label\"]\n",
    "#     # # create new dataframe with y and X\n",
    "#     # ...\n",
    "#     # # save the csv file\n",
    "#     with open(file_name_save, \"w\") as f:\n",
    "#         f.write(\"true_label,predicted_vector\\n\")\n",
    "#         for i in range(len(df)):\n",
    "#             f.write(\"{},{}\\n\".format(df[\"true_label\"][i], df[\"predicted_vector\"][i]))\n",
    "\n",
    "\n",
    "# def create_data_train_DR_ANN(df, file_name_save):\n",
    "#     # dimension reduce (reduce for classification task)\n",
    "#     ...\n",
    "#     # save the new dataframe\n",
    "#     ...\n",
    "#     # save the csv file\n",
    "\n",
    "\n",
    "# def create_data_train_Transformer(df, file_name_save):\n",
    "#     # transform X mn\n",
    "#     # ...\n",
    "#     # df[\"predicted_vector\"] = df[\"predicted_vector\"].apply(lambda x: x + np.argmax(x))   # [0.98, 0.01, 0.01] -> [0.98, 0.01, 0.01, 1, 0, 0]\n",
    "#     #\n",
    "#     with open(file_name_save, \"w\") as f:\n",
    "#         f.write(\"true_label,predicted_vector\\n\")\n",
    "#         for i in range(len(df)):\n",
    "#             f.write(\"{},{}\\n\".format(df[\"true_label\"][i], df[\"predicted_vector\"][i]))\n",
    "\n",
    "\n",
    "# test_df = load_data(\"~/Downloads/data_for_module2/test_not_aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harito/Downloads/data_for_module2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Convert the string of predicted_vector to a proper list of floats\n",
    "    df[\"predicted_vector\"] = df[\"predicted_vector\"].apply(lambda x: eval(x))\n",
    "    df.drop([\"path_to_image\", \"predicted_label\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def create_data_train_ANN(df, file_name_save):\n",
    "    X = np.array([np.array(x).flatten() for x in df['predicted_vector']])\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    # create new dataframe with y and X\n",
    "    new_df = pd.DataFrame(X)\n",
    "    new_df['label'] = y\n",
    "    \n",
    "    # save the csv file\n",
    "    new_df.to_csv(file_name_save, index=False)\n",
    "    # with open(file_name_save, 'w') as f:\n",
    "    #     f.write(\"label,predicted_vector\\n\")\n",
    "    #     for i in range(len(df)):\n",
    "    #         f.write(\"{},{}\\n\".format(df[\"label\"][i], df[\"predicted_vector\"][i]))\n",
    "\n",
    "def create_data_train_DR_ANN(df, file_name_save):\n",
    "    X = np.array([np.array(x).flatten() for x in df['predicted_vector']])\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    # dimension reduce (reduce for classification task)\n",
    "    # Option 1: PCA\n",
    "    pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Option 2: LDA\n",
    "    # lda = LDA(n_components=min(len(set(y) - 1), X.shape[1]))\n",
    "    # X_lda = lda.fit_transform(X, y)\n",
    "    \n",
    "    # Option 3: t-SNE\n",
    "    # tsne = TSNE(n_components=??, random_state=42)\n",
    "    # X_tsne = tsne.fit_transform(X)\n",
    "    \n",
    "    # Choose one of the above methods or combine them\n",
    "    X_reduced = X_pca  # or X_lda or X_tsne\n",
    "    # X_reduced = X_lda\n",
    "\n",
    "    # save the new dataframe\n",
    "    new_df = pd.DataFrame(X_reduced)\n",
    "    new_df['label'] = y\n",
    "    \n",
    "    # save the csv file\n",
    "    new_df.to_csv(file_name_save, index=False)\n",
    "\n",
    "def create_data_train_Transformer(df, file_name_save):\n",
    "    # transform X\n",
    "    # df[\"predicted_vector\"] = df[\"predicted_vector\"].apply(lambda x: x + [1 if i == np.argmax(x) else 0 for i in range(len(x))])\n",
    "    \n",
    "    with open(file_name_save, 'w') as f:\n",
    "        f.write(\"label,predicted_vector\\n\")\n",
    "        for i in range(len(df)):\n",
    "            f.write(\"{},{}\\n\".format(df[\"label\"][i], df[\"predicted_vector\"][i]))\n",
    "\n",
    "# fix lai de chuan bi du lieu cho model transformer\n",
    "test_df = load_data(\"~/Downloads/data_for_module2/test_not_aug.csv\")\n",
    "\n",
    "%cd ~/Downloads/data_for_module2\n",
    "# Example usage\n",
    "create_data_train_ANN(test_df, \"df_ann_test_data.csv\")\n",
    "create_data_train_DR_ANN(test_df, \"df_dr_ann_test_data.csv\")\n",
    "create_data_train_Transformer(test_df, \"df_transformer_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-4.326164722442627, -3.336007833480835, 7.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-6.909836292266846, -0.10185574740171432, 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-5.408203125, -1.994320034980774, 6.49257707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-5.0263237953186035, -2.326490879058838, 5.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[[-6.983879566192627, 5.36437463760376, -0.036...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                   predicted_vector\n",
       "0      2  [[-4.326164722442627, -3.336007833480835, 7.18...\n",
       "1      2  [[-6.909836292266846, -0.10185574740171432, 5....\n",
       "2      2  [[-5.408203125, -1.994320034980774, 6.49257707...\n",
       "3      2  [[-5.0263237953186035, -2.326490879058838, 5.7...\n",
       "4      2  [[-6.983879566192627, 5.36437463760376, -0.036..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 39)\n",
      "[ -4.32616472  -3.33600783   7.18650198  -7.65047455   2.33006692\n",
      "   2.62367773  -9.80081081   3.64352703   3.52408385  -9.21626759\n",
      "   0.63079673   6.04045963  -9.7001133    0.41957453   6.2976532\n",
      "  -9.94150734   0.20350178   6.4670887   -6.07121134  -1.14298558\n",
      "   6.11337137  -6.44479179  -0.41365007   5.78346777 -10.93817234\n",
      "   5.00597095   2.6089623  -11.15839767   3.30436683   3.34848619\n",
      "  -5.71532249  -1.46101451   5.17608023  -8.53942394  -1.72039652\n",
      "   7.67711163  -8.01943398   2.24353075   3.20311427]\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.array([np.array(x).flatten() for x in test_df['predicted_vector']])\n",
    "print(X_flatten.shape)\n",
    "print(X_flatten[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 13, 3)\n",
      "[[ -4.32616472  -3.33600783   7.18650198]\n",
      " [ -7.65047455   2.33006692   2.62367773]\n",
      " [ -9.80081081   3.64352703   3.52408385]\n",
      " [ -9.21626759   0.63079673   6.04045963]\n",
      " [ -9.7001133    0.41957453   6.2976532 ]\n",
      " [ -9.94150734   0.20350178   6.4670887 ]\n",
      " [ -6.07121134  -1.14298558   6.11337137]\n",
      " [ -6.44479179  -0.41365007   5.78346777]\n",
      " [-10.93817234   5.00597095   2.6089623 ]\n",
      " [-11.15839767   3.30436683   3.34848619]\n",
      " [ -5.71532249  -1.46101451   5.17608023]\n",
      " [ -8.53942394  -1.72039652   7.67711163]\n",
      " [ -8.01943398   2.24353075   3.20311427]]\n"
     ]
    }
   ],
   "source": [
    "X_transformer = np.array([np.array(x) for x in test_df['predicted_vector']])\n",
    "print(X_transformer.shape)\n",
    "print(X_transformer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for DR + ANN  \n",
    "\n",
    "X shape will be (-1, xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for Transformer  \n",
    "\n",
    "X shape will be (-1, 13, xx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_work#311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
