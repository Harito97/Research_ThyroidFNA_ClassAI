# Tổng quan tài liệu
tóm tắt trong 3 đến 5 câu: tập trung vào dữ liệu, phương pháp và kết quả

<!-- 2018 -->
## 3_
Bài báo tập trung vào việc sử dụng mạng nơ-ron tích chập (CNN) để xác định ung thư biểu mô nhú (PTCA) trên các phết tế bào học hút kim nhỏ tuyến giáp. Các nhà nghiên cứu đã sử dụng 370 vi ảnh từ các phết nhuộm Romanowsky/Pap, được chia thành hai loại: PTCA và không phải PTCA. Sau khi huấn luyện CNN với các vi ảnh này, mô hình đã đạt được độ nhạy 83,33\% trong việc phát hiện PTCA trên tập dữ liệu thử nghiệm. Kết quả nghiên cứu cho thấy CNN có tiềm năng trở thành một công cụ hỗ trợ hữu ích cho các nhà bệnh học trong việc chẩn đoán PTCA. 

<!-- 2019 -->
## 22_
Bài báo sử dụng tập dữ liệu gồm 908 mẫu sinh thiết kim nhỏ tuyến giáp, trong đó 109 mẫu được sử dụng làm tập kiểm tra và 799 mẫu được sử dụng để huấn luyện thuật toán. Phương pháp được đề xuất sử dụng hai mạng nơ-ron tích chập (CNN): CNN đầu tiên xác định các vùng hình ảnh có chứa các nhóm tế bào nang tuyến giáp, trong khi CNN thứ hai dự đoán khả năng ung thư tuyến giáp dựa trên các vùng được chọn. Thuật toán cũng dự đoán đồng thời loại Bethesda (TBS) và khả năng ung thư để cải thiện độ chính xác và độ tin cậy của dự đoán. Kết quả cho thấy hiệu suất của thuật toán tương đương với các chuyên gia tế bào học, với điểm số diện tích dưới đường cong (AUC) và điểm số trung bình chính xác (AP) tương đương. Đặc biệt, thuật toán dự đoán chính xác tất cả các trường hợp TBS 2 và 6 là lành tính và ác tính, bao gồm cả các trường hợp được các chuyên gia phân loại là không xác định (TBS 3 đến 5).

## 30_
Bài báo đã sử dụng tập dữ liệu gồm 279 hình ảnh tế bào học của các nốt tuyến giáp, được chia thành 159 trường hợp ung thư biểu mô tuyến giáp thể nhú (PTCs) và 120 trường hợp tổn thương lành tính. Các nhà nghiên cứu đã huấn luyện hai mô hình mạng nơ-ron tích chập sâu (DCNN), VGG-16 và Inception-v3, để phân biệt PTCs với các nốt lành tính dựa trên các hình ảnh tế bào học. Mô hình VGG-16 đạt được độ chính xác 97,66\% trên các hình ảnh phân mảnh và độ chính xác 95\% trên bệnh nhân. Các tác giả kết luận rằng mô hình DCNN VGG-16 cho thấy tiềm năng lớn trong việc hỗ trợ chẩn đoán PTC từ các hình ảnh tế bào học. Ngoài ra, nghiên cứu cũng phân tích các đặc điểm của nhân tế bào khối u, cho thấy chu vi, diện tích và cường độ pixel trung bình của PTCs cao hơn so với các nốt lành tính. 

<!-- 2020 -->
## 23_
Bài báo đã sử dụng tập dữ liệu gồm 908 hình ảnh toàn bộ slide (WSI) từ sinh thiết kim nhỏ tuyến giáp, chia thành tập huấn luyện 799 WSI và tập kiểm tra 109 WSI. Nghiên cứu sử dụng thuật toán học máy với hai mạng nơ-ron tích chập (CNN): CNN đầu tiên xác định các vùng quan tâm (ROI) chứa tế bào nang tuyến giáp, CNN thứ hai dự đoán khả năng ác tính dựa trên ROI. Kết quả cho thấy thuật toán có hiệu suất tương đương với các chuyên gia tế bào học trong việc dự đoán ung thư tuyến giáp, với diện tích dưới đường cong (AUC) là 0,932 so với 0,931 của chuyên gia. Ngoài ra, khi kết hợp thuật toán với chẩn đoán của bác sĩ từ hồ sơ bệnh án điện tử, AUC tăng lên 0,962, cho thấy tiềm năng của thuật toán như một công cụ hỗ trợ chẩn đoán. 

<!-- 2021 -->
## 2_
Bài báo sử dụng tập dữ liệu gồm 367 hình ảnh tế bào học nhuộm hematoxylin-eosin (H&E), bao gồm 222 trường hợp ung thư biểu mô nhú tuyến giáp (PTC) và 145 trường hợp tổn thương lành tính (Non-PTC). Nghiên cứu đề xuất một hệ thống chẩn đoán hỗ trợ máy tính (CAD) tự động để phân biệt PTC với tổn thương lành tính từ hình ảnh tế bào học kỹ thuật số FNAC được xử lý bằng ThinPrep® bằng cách sử dụng các framework CNN học sâu. Các tác giả đã sử dụng sáu mô hình CNN học sâu được phát triển gần đây - ResNet, DenseNet và Inception - kết hợp với học tập tập hợp để tăng cường độ chính xác dự đoán. Kết quả cho thấy DenseNet161 đạt hiệu suất tốt nhất, với độ chính xác trung bình là 0,9556, độ nhạy 0,9734 và độ đặc hiệu 0,9405 trên tập dữ liệu thử nghiệm. Ngoài ra, học tập tập hợp kết hợp bộ phân loại AdaBoost với nhiều mô hình CNN đã tăng hiệu suất dự đoán, đạt độ chính xác lên tới 0,9971. 

<!-- 2022 -->
## 8_
Bài báo sử dụng tập dữ liệu gồm 360 mẫu Whole Slide Images (WSIs) từ sinh thiết kim nhỏ tuyến giáp, được chia thành 222 trường hợp lành tính và 138 trường hợp ác tính. Các tác giả đề xuất một hệ thống chẩn đoán hỗ trợ máy tính (CAD) hai giai đoạn sử dụng mạng nơ-ron tích chập (CNN). Giai đoạn đầu tiên sử dụng YOLO V4 để phát hiện các vùng nghi ngờ ác tính, trong khi giai đoạn thứ hai sử dụng EfficientNet để phân loại chính xác các vùng này thành lành tính hoặc ác tính. Kết quả cho thấy hệ thống hai giai đoạn đạt được độ chính xác 81,84\%, cao hơn 3,16\% so với việc chỉ sử dụng mạng phát hiện YOLO V4. Nghiên cứu kết luận rằng hệ thống CAD hai giai đoạn này cung cấp một giải pháp mới cho việc sàng lọc ung thư tuyến giáp tự động và có giá trị lâm sàng nhất định. 

## 31_
Bài báo sử dụng tập dữ liệu gồm 908 mẫu sinh thiết kim nhỏ tuyến giáp (FNAB), trong đó 799 mẫu được dùng để huấn luyện thuật toán và 109 mẫu được dùng để kiểm tra. Phương pháp được sử dụng là một phần mềm sàng lọc dựa trên thuật toán học máy với hai thành phần chính: mạng nơ-ron tích chập (CNN) để xác định các vùng quan tâm (ROI) chứa tế bào nang tuyến giáp và giao diện người dùng đồ họa để hiển thị 100 ROI được xác định là chứa thông tin chẩn đoán nhiều nhất. Kết quả cho thấy sự tương đồng gần như hoàn hảo (j = 0.924) giữa chẩn đoán dựa trên hình ảnh toàn bộ slide (WSI) và chẩn đoán dựa trên 100 ROI được chọn bởi thuật toán. Điều này cho thấy tiềm năng của phần mềm sàng lọc trong việc hỗ trợ chẩn đoán ung thư tuyến giáp, giảm khối lượng công việc của các nhà tế bào học. 

<!-- 2023 -->
## 13_
Bài báo đã sử dụng tập dữ liệu gồm 964 hình ảnh toàn bộ slide (WSI) của các mẫu sinh thiết kim nhỏ tuyến giáp, được quét bằng máy quét Leica AT-2 ở độ phóng đại 40x, để huấn luyện một mô hình học sâu (deep learning). Mô hình này, dựa trên kiến trúc MobileNetV2, được thiết kế để phân loại ung thư tuyến giáp từ hình ảnh được chụp bằng điện thoại di động gắn vào kính hiển vi. Kết quả cho thấy việc bổ sung kỹ thuật tăng cường màu sắc (color augmentation) trong quá trình huấn luyện đã cải thiện đáng kể hiệu suất của mô hình khi áp dụng cho hình ảnh từ điện thoại di động, đạt được AUC 96,0\% so với 89,5\% của mô hình cơ sở. Kết quả này cho thấy tiềm năng của việc sử dụng điện thoại di động kết hợp với học máy để chẩn đoán ung thư tuyến giáp, đặc biệt là ở các khu vực có nguồn lực hạn chế. Ngoài ra, nghiên cứu cũng chỉ ra rằng mô hình đạt hiệu suất tối ưu sau khi phân tích 15 vùng quan tâm (ROI) trên mỗi slide, cho thấy quy trình thu thập dữ liệu ROI sẽ không tốn nhiều thời gian. 

## 15_
Bài báo sử dụng tập dữ liệu gồm 1928 hình ảnh toàn bộ slide (WSI) từ các mẫu sinh thiết kim nhỏ tuyến giáp (FNAB) được thu thập từ năm 2008 đến 2018. Nghiên cứu sử dụng thuật toán học sâu với hai mạng nơ-ron tích chập (CNN). CNN đầu tiên, được gọi là CNN thông tin, xác định các vùng quan tâm (ROI) chứa các tế bào nang tuyến giáp, trong khi CNN thứ hai phân loại FNAB thành ba loại lâm sàng: lành tính, không xác định và ác tính. Thuật toán đạt hiệu suất tương đương với các chuyên gia tế bào học trong việc dự đoán ung thư tuyến giáp, với khả năng sàng lọc 45,1\% trường hợp là lành tính hoặc ác tính với tỷ lệ nguy cơ ác tính (ROM) lần lượt là 2,7\% và 94,7\%. Thuật toán cũng có thể được sử dụng như một xét nghiệm bổ trợ để giảm số lượng trường hợp không xác định, giảm 21,3\% số trường hợp không xác định với ROM là 1,8\% cho loại lành tính.

## 17_
Bài báo đã sử dụng tập dữ liệu gồm 577 hình ảnh toàn bộ slide (WSI) từ các mẫu mô đông lạnh phẫu thuật tuyến giáp. Các nhà nghiên cứu đã phát triển một hệ thống chẩn đoán dựa trên trí tuệ nhân tạo (AI) sử dụng các kỹ thuật thị giác máy tính kết hợp với mạng nơ-ron học sâu và máy vectơ hỗ trợ (SVM) để tự động nhận dạng tất cả các loại bệnh tuyến giáp. Hệ thống này bao gồm ba giai đoạn chính: thuật toán phân loại bệnh hoàn chỉnh ở cấp độ slide, phân loại lành tính và ác tính ở cấp độ bản vá, và phân loại phân nhóm ở cấp độ bản vá. Kết quả cho thấy phương pháp được đề xuất có thể chẩn đoán chính xác các nốt tuyến giáp trong quá trình phẫu thuật, với độ nhạy 72,65\%, độ đặc hiệu 100,0\% và AUC là 86,32\% trên 191 slide thử nghiệm. Đối với chẩn đoán phân nhóm, AUC tốt nhất là 99,46\% đối với ung thư tuyến giáp thể tủy, với thời gian trung bình là 237,6 giây cho mỗi slide.

## 29_
Bài báo sử dụng tập dữ liệu gồm 1535 cụm tế bào tuyến giáp (1128 lành tính và 407 ác tính) từ 124 bệnh nhân để huấn luyện và thử nghiệm thuật toán học máy (MLA). Các nhà nghiên cứu đã sử dụng kỹ thuật chụp cắt lớp quang học nhiễu xạ tương quan để thu được hình ảnh nhuộm Papanicolaou và phân bố chỉ số khúc xạ (RI) ba chiều của các mẫu sinh thiết kim nhỏ tuyến giáp (FNAB). MLA được thiết kế để phân loại các cụm tế bào lành tính và ác tính bằng cách sử dụng hình ảnh màu, hình ảnh RI hoặc cả hai. Kết quả cho thấy MLA sử dụng kết hợp thông tin từ cả hình ảnh màu và hình ảnh RI đạt độ chính xác 100\% trong việc phân loại các cụm tế bào. Nghiên cứu kết luận rằng việc kết hợp dữ liệu hình ảnh RI và dữ liệu hình ảnh màu nhuộm Papanicolaou có thể cải thiện độ chính xác của MLA trong chẩn đoán ung thư tuyến giáp từ các mẫu FNAB. 

<!-- 2024 -->
## 4_
Bài báo sử dụng tập dữ liệu gồm 17.966 hình ảnh toàn bộ slide (WSI) từ 7.420 bệnh nhân, được chia thành tập huấn luyện, tập xác nhận nội bộ, ba tập xác nhận bên ngoài và một tập xác nhận tiền cứu. Nghiên cứu phát triển một hệ thống hỗ trợ AI có tên là ThyroPower, sử dụng mạng nơ-ron học sâu (deep learning) để chẩn đoán các nốt tuyến giáp theo Hệ thống Báo cáo Bethesda về Tế bào học Tuyến giáp (TBSRTC). ThyroPower trích xuất các đặc trưng ở cấp độ tế bào bằng mô hình PAGIN, sau đó kết hợp hai mô hình phân loại cấp WSI (Random Forest và Top-N Feature) để đưa ra quyết định chẩn đoán cuối cùng. Kết quả cho thấy ThyroPower đạt hiệu suất cao trong việc phân biệt lành tính với TBSRTC III+ (AUROC 0,930 cho xác nhận nội bộ và 0,944-0,971 cho xác nhận bên ngoài) và TBSRTC V+ (AUROC 0,990 cho xác nhận nội bộ và 0,965-0,991 cho xác nhận bên ngoài). Hệ thống cũng cải thiện đáng kể độ chính xác và độ đặc hiệu của các nhà tế bào học ít kinh nghiệm trong nghiên cứu tiền cứu. 

## 28_
Bài báo sử dụng tập dữ liệu gồm các mẫu tế bào tuyến giáp người được nhuộm bằng xanh methylen (MB) và chụp ảnh phân cực huỳnh quang (Fpol). Các nhà nghiên cứu đã phát triển một mô hình mạng nơ-ron tích chập U-Net 2D để phân đoạn tế bào tự động từ hình ảnh Fpol, nhằm giảm thời gian phân tích dữ liệu và đưa công nghệ Fpol MB vào ứng dụng lâm sàng. Kết quả cho thấy mô hình U-Net phân đoạn được 15,8\% số tế bào nhiều hơn so với chuyên gia thực hiện thủ công.  Mặc dù diện tích tế bào được phân đoạn bởi mô hình U-Net nhỏ hơn 6\% so với phương pháp thủ công, nhưng giá trị Fpol thu được từ hai phương pháp không có sự khác biệt thống kê đáng kể. Nghiên cứu kết luận rằng việc triển khai phân tích tế bào tự động giúp chẩn đoán dựa trên phân cực huỳnh quang định lượng trở nên khả thi về mặt lâm sàng, giảm thời gian xử lý dữ liệu từ một giờ xuống còn 10 giây. 
