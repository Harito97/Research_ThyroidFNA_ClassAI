{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các công việc triển khai\n",
    "\n",
    "Trong file này sẽ thực hiện các việc.\n",
    "\n",
    "- Cho data ảnh từ các tập train, valid, test qua module 1 và save lại kết quả vào 3 file csv tương ứng.\n",
    "- Cụ thể với mỗi một ảnh, ảnh gốc sẽ resize về 1024x768, cắt lấy 12 miếng theo lưới 256x256. Như vậy tổng cộng thu được 13 miếng (tất cả resize về 224x224). Cuối cùng 13 miếng này cho qua module 1 thu được 13 vector 3 chiều (tương ứng cho xác suất thuộc về 3 nhãn của 1 miếng ảnh). Như vậy 1 bản ghi sẽ được lưu trữ dưới dạng 13 chiều 3 chiều này (tức 39 chiều).\n",
    "- Sau khi đã save 3 file csv cho mỗi tập. Thực hiện phân tích phân phối dữ liệu các trường thu được (trước hết chỉ thực hiện với 3 chiều đầu tiên - tức chỉ cho miếng toàn cục nhất). Sau đó mới phân tích đến cả 39 chiều cùng lúc.\n",
    "- Các thông tin đem phân tích có thể như phân phối của chiều dữ liệu này có phải phân phối chuẩn hay không. Hệ số tương quan của các chiều này với nhau (tại vì chúng có thể có hiện tượng đa cộng tuyến).\n",
    "- Sau khi xác định được phân phối của dữ liệu thì đề xuất các phương pháp để tạo sinh thêm dữ liệu mới dựa trên dữ liệu phân phối đã có."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo model của module 1 để giúp dự đoán nhãn của 1 ảnh\n",
    "!pwd\n",
    "# import os\n",
    "# os.chdir(\"../../src/models/module1\")\n",
    "# !pwd\n",
    "\n",
    "# import torch\n",
    "# from efficient_net import H0_EfficientNetB0\n",
    "\n",
    "# model = H0_EfficientNetB0()\n",
    "# ''' \n",
    "# Model là 1 mạng CNN EfficientNetB0 thông thường với đầu ra phân loại 3 nhãn\n",
    "# ''' \n",
    "# model_path = '../../weights/1725034685_phase2_280824_module1_H0_EfficientNetB0/best_loss.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming H0_EfficientNetB0 is imported correctly\n",
    "os.chdir(\"../../src/models/module1\")\n",
    "from efficient_net import H0_EfficientNetB0\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = H0_EfficientNetB0()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "def process_image(image_path, model, device):\n",
    "    # Resize to 1024x768 and create 12 256x256 patches + 1 full image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = image.resize((1024, 768))\n",
    "    patches = []\n",
    "    patches.append(image)\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "            patch = image.crop((j*256, i*256, (j+1)*256, (i+1)*256))\n",
    "            patches.append(patch)\n",
    "    \n",
    "    # Resize all to 224x224 and process\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # results = []\n",
    "    # for patch in patches:\n",
    "    #     input_tensor = transform(patch).unsqueeze(0).to(device)\n",
    "    #     with torch.no_grad():\n",
    "    #         output = model(input_tensor)\n",
    "    #     probabilities = output\n",
    "    #     # probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    #     results.extend(probabilities.cpu().numpy().flatten())\n",
    "    \n",
    "    results = []\n",
    "    # Convert all patches to tensors and stack them into a single batch\n",
    "    batch_tensor = torch.stack([transform(patch) for patch in patches]).to(device)\n",
    "    # Run the model inference on the entire batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_tensor)\n",
    "    # Since each output corresponds to one patch, you can directly extract probabilities\n",
    "    probabilities = outputs\n",
    "    # If you want softmax probabilities, you can uncomment the following line:\n",
    "    # probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    # Flatten the results and extend to the results list\n",
    "    results.extend(probabilities.cpu().numpy().flatten())\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_dataset(data_dir, model, device, output_file):\n",
    "    results = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                result = process_image(image_path, model, device)\n",
    "                results.append([image_path] + result)\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=['image_path'] + [f'dim_{i}' for i in range(39)])\n",
    "    df.to_csv(output_file, index=False)\n",
    "    return df\n",
    "\n",
    "def analyze_distribution(df):\n",
    "    # Analyze first 3 dimensions (global patch)\n",
    "    for i in range(3):\n",
    "        col = f'dim_{i}'\n",
    "        _, p_value = stats.normaltest(df[col])\n",
    "        print(f\"Normality test for {col}: p-value = {p_value}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.histplot(df[col], kde=True)\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Correlation matrix for all 39 dimensions\n",
    "    corr_matrix = df.iloc[:, 1:].corr()\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "    plt.title(\"Correlation Matrix of All Dimensions\")\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    model_path = '../../weights/1725034685_phase2_280824_module1_H0_EfficientNetB0/best_loss.pth'\n",
    "    model, device = load_model(model_path)\n",
    "    \n",
    "    data_dirs = {\n",
    "        'train': '../../data/train',\n",
    "        'valid': '../../data/valid',\n",
    "        'test': '../../data/test'\n",
    "    }\n",
    "    \n",
    "    for split, data_dir in data_dirs.items():\n",
    "        output_file = f'../../data/processed/{split}_features.csv'\n",
    "        df = process_dataset(data_dir, model, device, output_file)\n",
    "        print(f\"Processed {split} dataset. Shape: {df.shape}\")\n",
    "        \n",
    "        analyze_distribution(df)\n",
    "    \n",
    "    print(\"Processing and analysis complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
