{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Summary about experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(BASE ON THE EFFICIENT_NET_B0 - WITH GAP + HIDDEN LAYER (97, 9, 7) + DENSE(3)) + BATCH SIZE = 144\n",
    "## Ex1\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex2\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex3\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex4\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex5\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex6\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex7\n",
    "\n",
    "Combine version (Assemble version)\n",
    "- Data: output of model at Ex3 (1, 3), Ex4 (8, 3), Ex5 (12, 3)\n",
    "```markdown\n",
    "each       detect   |dataver1 ((1, 3, 768, 1024) -> (1, 3, 224, 224))\n",
    "image from -->-->-->|dataver2_image ((8, 3, ??, ??) -> (8, 3, 224, 224))\n",
    "dataver0   cluster  |dataver2_patch ((12, 3, 256, 256) -> (12, 3, 224, 224))\n",
    "\n",
    "   |(1, 3)     \n",
    "-->|(8, 3)  --> (21, 3) -> (63) -> (3) \n",
    "   |(12, 3)    \n",
    "```\n",
    "- Model: \n",
    "   - Type 1 use 3 model independence of Ex4, 5, 6\n",
    "   - Type 2 use best model in 3 model of Ex4, 5, 6\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(BASE ON THE EFFICIENT_NET_B0 - WITH GAP + **HIDDEN LAYER (0)** + DENSE(3)) + BATCH SIZE = 144\n",
    "## Ex8\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex9\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex10\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex11\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex12\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex13\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(BASE ON THE EFFICIENT_NET_B0 - WITH GAP + HIDDEN LAYER (97, 9, 7) + DENSE(3)) + **BATCH SIZE = 32**\n",
    "## Ex15\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex16\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex17\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex18\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex19\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex20\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.1)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex21\n",
    "\n",
    "Combine version (Assemble version)\n",
    "- Data: output of model at Ex3 (1, 3), Ex4 (8, 3), Ex5 (12, 3)\n",
    "```markdown\n",
    "each       detect   |dataver1 ((1, 3, 768, 1024) -> (1, 3, 224, 224))\n",
    "image from-->-->|dataver2_image ((8, 3, ??, ??) -> (8, 3, 224, 224))\n",
    "dataver0   cluster  |dataver2_patch ((12, 3, 256, 256) -> (12, 3, 224, 224))\n",
    "\n",
    "   |(1, 3)     \n",
    "-->|(8, 3)  --> (21, 3) -> (63) -> (3) \n",
    "   |(12, 3)    \n",
    "```\n",
    "- Model: \n",
    "   - Type 1 use 3 model independence of Ex4, 5, 6\n",
    "   - Type 2 use best model in 3 model of Ex4, 5, 6\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 32, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(BASE ON THE EFFICIENT_NET_B0 - WITH GAP + **HIDDEN LAYER (0)** + DENSE(3)) + BATCH SIZE = 32\n",
    "## Ex22\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex23\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex24\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex25\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex26\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex27\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(BASE ON THE EFFICIENT_NET_B7 - WITH GAP + **HIDDEN LAYER (0)** + DENSE(3)) + BATCH SIZE = 32 for Ex29 & Ex31. BATCH SIZE = 16 for Ex30, Ex32, Ex33, Ex34 (as out of the memory of GPU)\n",
    "## Ex29\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex30\n",
    "\n",
    "With batch size = 16 -> about 10168MiB of GPU\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex31\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex32\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex33\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex34\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB7, type CNN, no hidden layer between GAP and dense classifier (3)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex36..41\n",
    "\n",
    "Like Ex29..34 but with base model is H97_9_7_EfficientNetB7 (dropout 0.5 - as model has too many parameters -> make over fit).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion about experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1 vs Ex2 | Ex3 vs Ex4\n",
    "\n",
    "fine tune last layer or retrain model better\n",
    "\n",
    "## Ex1 vs Ex3 | Ex2 vs Ex4\n",
    "\n",
    "is draw cell cluster bounding box better ??\n",
    "\n",
    "## Ex1 2 3 4 vs Ex5\n",
    "\n",
    "only look in the cell cluster be cropped: better ??\n",
    "(zoom x1.3 -> x?? times)\n",
    "validation by mean of 8 output (8, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex1 2 3 4 vs Ex6\n",
    "\n",
    "zoom in at level x12 times (with bounding box draw): better ??\n",
    "validation by mean of 12 output (12, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex5 vs Ex6\n",
    "\n",
    "which way to look is better\n",
    "\n",
    "## Ex1...6 vs Ex7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1..7 vs Ex8..14:\n",
    "\n",
    "Eff (GAP) + hidden (97, 7, 3) + class (3)\n",
    "\n",
    "vs\n",
    "\n",
    "Eff (GAP) + hidden (0) + class (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex8 vs Ex9 | Ex10 vs Ex11\n",
    "\n",
    "fine tune last layer or retrain model better\n",
    "\n",
    "## Ex8 vs Ex10 | Ex9 vs Ex11\n",
    "\n",
    "is draw cell cluster bounding box better ??\n",
    "\n",
    "## Ex8 Ex9 Ex10 Ex11 vs Ex12\n",
    "\n",
    "only look in the cell cluster be cropped: better ??\n",
    "(zoom x1.3 -> x?? times)\n",
    "validation by mean of 8 output (8, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex8 Ex9 Ex10 Ex11 vs Ex13\n",
    "\n",
    "zoom in at level x12 times (with bounding box draw): better ??\n",
    "validation by mean of 12 output (12, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex12 vs Ex13\n",
    "\n",
    "which way to look is better\n",
    "\n",
    "## Ex8...13 vs Ex 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1..7 + Ex8..14 vs Ex15..:\n",
    "**batch size = 144**\n",
    "Eff (GAP) + hidden (97, 7, 3) + class (3)\n",
    "+\n",
    "Eff (GAP) + hidden (0) + class (3) \n",
    "\n",
    "vs \n",
    "\n",
    "**batch size = 32**\n",
    "Eff (GAP) + hidden (97, 7, 3) + class (3)\n",
    "+\n",
    "Eff (GAP) + hidden (0) + class (3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
