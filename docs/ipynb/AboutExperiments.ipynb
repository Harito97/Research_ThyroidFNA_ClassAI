{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Summary about experiments\n",
    "\n",
    "## Ex1\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: finetune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex2\n",
    "\n",
    "- Data: dataver0/train & dataver0/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex3\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: fine tune the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex4\n",
    "\n",
    "- Data: dataver1/train & dataver1/val\n",
    "- Model: retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex5\n",
    "\n",
    "- Data: dataver2_image/train & dataver2_image/val (top 5 cropped image)\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex6\n",
    "\n",
    "- Data: dataver2_patch/train & dataver2_patch/val\n",
    "- Model: (start train by model at Ex4 ?should be) retrain the EfficientNetB0, type CNN, last layer dense(97) + relu + dropout(0.5)\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4\n",
    "\n",
    "## Ex7\n",
    "\n",
    "Combine version (Assemble version)\n",
    "- Data: output of model at Ex3 (1, 3), Ex4 (8, 3), Ex5 (12, 3)\n",
    "```markdown\n",
    "each       detect   |dataver1 ((1, 3, 768, 1024) -> (1, 3, 224, 224))\n",
    "image from -->-->-->|dataver2_image ((8, 3, ??, ??) -> (8, 3, 224, 224))\n",
    "dataver0   cluster  |dataver2_patch ((12, 3, 256, 256) -> (12, 3, 224, 224))\n",
    "\n",
    "   |(1, 3)     \n",
    "-->|(8, 3)  --> (21, 3) -> (63) -> (3) \n",
    "   |(12, 3)    \n",
    "```\n",
    "- Model: \n",
    "   - Type 1 use 3 model independence of Ex4, 5, 6\n",
    "   - Type 2 use best model in 3 model of Ex4, 5, 6\n",
    "- Train: 100 epochs, learning rate 0.001, optimizer adam, batch size 144, weight of loss follow by number of (B2, B5, B6), patience 10 epoch\n",
    "- Augmentation: resize(224x224), horizontal flip, vertical flip, rotation range 180\n",
    "- Classes: B2, B5, B6\n",
    "- Device run: 16GB RAM GPU - Tesla T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion about experiment\n",
    "\n",
    "## Ex1 vs Ex2 | Ex3 vs Ex4\n",
    "\n",
    "fine tune last layer or retrain model better\n",
    "\n",
    "## Ex1 vs Ex3 | Ex2 vs Ex4\n",
    "\n",
    "is draw cell cluster bounding box better ??\n",
    "\n",
    "## Ex1 2 3 4 vs Ex5\n",
    "\n",
    "only look in the cell cluster be cropped: better ??\n",
    "(zoom x1.3 -> x?? times)\n",
    "validation by mean of 8 output (8, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex1 2 3 4 vs Ex6\n",
    "\n",
    "zoom in at level x12 times (with bounding box draw): better ??\n",
    "validation by mean of 12 output (12, 3) -> (1, 3) -> arg max\n",
    "\n",
    "## Ex5 vs Ex6\n",
    "\n",
    "which way to look is better\n",
    "\n",
    "# Ex1...6 vs Ex7\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
