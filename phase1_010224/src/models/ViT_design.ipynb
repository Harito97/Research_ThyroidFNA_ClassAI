{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.cls_token: Parameter containing:\n",
      "tensor([[[0., 0., 0., 0., 0., 0.]]], requires_grad=True)\n",
      "self.pos_embedding: Parameter containing:\n",
      "tensor([[[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]]], requires_grad=True)\n",
      "x: tensor([[[-0.9285, -0.8449, -0.5990],\n",
      "         [-0.2176,  1.1140,  0.7230],\n",
      "         [ 0.2371,  0.2902, -0.4879],\n",
      "         [ 1.0518, -1.4160, -1.5377],\n",
      "         [-0.5393,  0.7882, -2.0191],\n",
      "         [-0.8573,  0.2572,  0.9746],\n",
      "         [-1.3147, -0.3570, -1.3314],\n",
      "         [-0.8846, -1.3643, -1.0141],\n",
      "         [-0.6322, -0.7458, -0.2021],\n",
      "         [-0.6436, -0.5469, -0.1400],\n",
      "         [ 2.1159,  1.1580,  0.3426],\n",
      "         [ 1.1757, -0.9629,  1.1513],\n",
      "         [ 0.1856,  0.7930,  0.3793]],\n",
      "\n",
      "        [[-0.9506,  1.0818,  0.9391],\n",
      "         [ 0.4436, -0.0810,  1.4855],\n",
      "         [-0.6323,  0.5710, -1.7938],\n",
      "         [-1.6074,  0.2454, -0.1174],\n",
      "         [ 0.9761, -0.1034,  1.0366],\n",
      "         [-0.0790,  0.0923,  1.3307],\n",
      "         [ 1.0788, -0.8058, -1.2150],\n",
      "         [ 2.0364, -1.0549,  0.0071],\n",
      "         [-0.8815, -0.8505, -1.8106],\n",
      "         [ 0.0223, -0.2783, -1.8831],\n",
      "         [-1.8877, -1.8040, -0.7424],\n",
      "         [-1.0072,  0.7944, -0.3153],\n",
      "         [-0.4624,  0.7085,  0.4749]]])\n",
      "torch.Size([2, 13, 3])\n",
      "torch.Size([2, 1, 6])\n",
      "tensor([[[0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 0., 1.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 0., 1.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.]]])\n",
      "After concat vs one_hot: tensor([[[ 0.0000,  0.0000,  1.0000, -0.9285, -0.8449, -0.5990],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.2176,  1.1140,  0.7230],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.2371,  0.2902, -0.4879],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0518, -1.4160, -1.5377],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5393,  0.7882, -2.0191],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.8573,  0.2572,  0.9746],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.3147, -0.3570, -1.3314],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.8846, -1.3643, -1.0141],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6322, -0.7458, -0.2021],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6436, -0.5469, -0.1400],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.1159,  1.1580,  0.3426],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.1757, -0.9629,  1.1513],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1856,  0.7930,  0.3793]],\n",
      "\n",
      "        [[ 0.0000,  1.0000,  0.0000, -0.9506,  1.0818,  0.9391],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.4436, -0.0810,  1.4855],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.6323,  0.5710, -1.7938],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6074,  0.2454, -0.1174],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.9761, -0.1034,  1.0366],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.0790,  0.0923,  1.3307],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0788, -0.8058, -1.2150],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.0364, -1.0549,  0.0071],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.8815, -0.8505, -1.8106],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.0223, -0.2783, -1.8831],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8877, -1.8040, -0.7424],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0072,  0.7944, -0.3153],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4624,  0.7085,  0.4749]]])\n",
      "After concat vs cls_token: tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.9285, -0.8449, -0.5990],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.2176,  1.1140,  0.7230],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.2371,  0.2902, -0.4879],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0518, -1.4160, -1.5377],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5393,  0.7882, -2.0191],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.8573,  0.2572,  0.9746],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.3147, -0.3570, -1.3314],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.8846, -1.3643, -1.0141],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6322, -0.7458, -0.2021],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6436, -0.5469, -0.1400],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.1159,  1.1580,  0.3426],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.1757, -0.9629,  1.1513],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1856,  0.7930,  0.3793]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.9506,  1.0818,  0.9391],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.4436, -0.0810,  1.4855],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.6323,  0.5710, -1.7938],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6074,  0.2454, -0.1174],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.9761, -0.1034,  1.0366],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.0790,  0.0923,  1.3307],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0788, -0.8058, -1.2150],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.0364, -1.0549,  0.0071],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.8815, -0.8505, -1.8106],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.0223, -0.2783, -1.8831],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8877, -1.8040, -0.7424],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0072,  0.7944, -0.3153],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4624,  0.7085,  0.4749]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "torch.Size([2, 14, 6])\n",
      "After add pos_embedding: tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.9285, -0.8449, -0.5990],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.2176,  1.1140,  0.7230],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.2371,  0.2902, -0.4879],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0518, -1.4160, -1.5377],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5393,  0.7882, -2.0191],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.8573,  0.2572,  0.9746],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.3147, -0.3570, -1.3314],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.8846, -1.3643, -1.0141],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6322, -0.7458, -0.2021],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6436, -0.5469, -0.1400],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.1159,  1.1580,  0.3426],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.1757, -0.9629,  1.1513],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1856,  0.7930,  0.3793]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.9506,  1.0818,  0.9391],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.4436, -0.0810,  1.4855],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.6323,  0.5710, -1.7938],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6074,  0.2454, -0.1174],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.9761, -0.1034,  1.0366],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.0790,  0.0923,  1.3307],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.0788, -0.8058, -1.2150],\n",
      "         [ 1.0000,  0.0000,  0.0000,  2.0364, -1.0549,  0.0071],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.8815, -0.8505, -1.8106],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.0223, -0.2783, -1.8831],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8877, -1.8040, -0.7424],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0072,  0.7944, -0.3153],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4624,  0.7085,  0.4749]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 14, 6])\n",
      "torch.Size([2, 14, 6])\n",
      "torch.Size([2, 3])\n",
      "tensor([[-0.4736, -0.5223, -0.3913],\n",
      "        [-0.6690, -0.2767, -0.3441]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        mlp_dim,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            # torch.zeros(1, (image_size // patch_size) ** 2 + 1, dim)\n",
    "            torch.zeros(1, 13 + 1, dim)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=dim,\n",
    "                nhead=heads,\n",
    "                dim_feedforward=mlp_dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,  # Đặt batch_first=True\n",
    "            ),\n",
    "            num_layers=depth,\n",
    "        )\n",
    "        self.head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):   # x shape (2, 13, 3) = (batch_size, num_patches, dim)\n",
    "        print(f\"self.cls_token: {self.cls_token}\")\n",
    "        print(f\"self.pos_embedding: {self.pos_embedding}\")\n",
    "        print(f\"x: {x}\")\n",
    "        print(x.shape)\n",
    "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        # cls_tokens = x[:, 0].unsqueeze(1)\n",
    "        print(cls_tokens.shape)\n",
    "\n",
    "        one_hot = F.one_hot(torch.argmax(x, dim=2), num_classes=x.size(2)).float()\n",
    "        print(one_hot)\n",
    "        x = torch.cat((one_hot, x), dim=2)\n",
    "        print(f\"After concat vs one_hot: {x}\")\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        print(f\"After concat vs cls_token: {x}\")\n",
    "        print(x.shape)\n",
    "        x += self.pos_embedding\n",
    "        print(f\"After add pos_embedding: {x}\")\n",
    "        print(x.shape)\n",
    "        x = self.transformer(x)\n",
    "        print(x.shape)\n",
    "        x = self.head(x[:, 0])\n",
    "        print(x.shape)\n",
    "        print(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "model = ViT(\n",
    "   num_classes=3, dim=6, depth=3, heads=2, mlp_dim=12\n",
    ")\n",
    "x = torch.randn(2, 13, 3)  # Một batch gồm 2 ảnh\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Giả sử model là một đối tượng mô hình ViT\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(97*3)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.cls_token: Parameter containing:\n",
      "tensor([[[0., 0., 0., 0., 0., 0.]]], requires_grad=True)\n",
      "self.pos_embedding: Parameter containing:\n",
      "tensor([[[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]]], requires_grad=True)\n",
      "x: tensor([[[ 1.1078,  0.6078, -0.7931],\n",
      "         [-0.6969, -1.3807,  1.0727],\n",
      "         [-0.6976, -1.2132,  0.7139],\n",
      "         [ 0.6209, -1.0919,  0.7523],\n",
      "         [ 0.0340,  1.2201, -0.1346],\n",
      "         [-1.6126, -0.9207, -1.0670],\n",
      "         [-0.5852,  1.7451,  0.6311],\n",
      "         [-0.4041, -1.2397,  1.8388],\n",
      "         [ 1.9605,  0.1487, -0.1732],\n",
      "         [ 0.8742,  0.8293,  0.5248],\n",
      "         [-0.1507, -0.0778, -0.1293],\n",
      "         [ 0.8734, -2.1189, -0.0973],\n",
      "         [ 0.3704,  1.2938, -0.4054]],\n",
      "\n",
      "        [[-0.5379,  0.8660, -1.4143],\n",
      "         [-0.4281, -0.1816, -0.8599],\n",
      "         [-0.7000, -1.1978, -0.8845],\n",
      "         [-1.0709, -0.0401, -0.3645],\n",
      "         [-1.8671, -0.7738,  0.4051],\n",
      "         [-0.5325,  0.7534,  0.0585],\n",
      "         [-1.0775, -0.3009, -0.1811],\n",
      "         [-0.1016,  0.9733, -1.0202],\n",
      "         [ 0.1264,  0.4393, -0.8988],\n",
      "         [-3.9854,  0.8901, -0.6313],\n",
      "         [-0.1501,  0.5025, -0.2411],\n",
      "         [ 0.0192, -0.0141,  0.4895],\n",
      "         [-0.7944,  1.1266, -0.7364]]])\n",
      "torch.Size([2, 13, 3])\n",
      "torch.Size([2, 1, 6])\n",
      "tensor([[[1., 0., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [1., 0., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 0., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [0., 0., 1.],\n",
      "         [0., 1., 0.]]])\n",
      "After concat vs one_hot: tensor([[[ 1.0000,  0.0000,  0.0000,  1.1078,  0.6078, -0.7931],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6969, -1.3807,  1.0727],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6976, -1.2132,  0.7139],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.6209, -1.0919,  0.7523],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.0340,  1.2201, -0.1346],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6126, -0.9207, -1.0670],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5852,  1.7451,  0.6311],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.4041, -1.2397,  1.8388],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.9605,  0.1487, -0.1732],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8742,  0.8293,  0.5248],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1507, -0.0778, -0.1293],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8734, -2.1189, -0.0973],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.3704,  1.2938, -0.4054]],\n",
      "\n",
      "        [[ 0.0000,  1.0000,  0.0000, -0.5379,  0.8660, -1.4143],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4281, -0.1816, -0.8599],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.7000, -1.1978, -0.8845],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0709, -0.0401, -0.3645],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8671, -0.7738,  0.4051],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5325,  0.7534,  0.0585],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.0775, -0.3009, -0.1811],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1016,  0.9733, -1.0202],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1264,  0.4393, -0.8988],\n",
      "         [ 0.0000,  1.0000,  0.0000, -3.9854,  0.8901, -0.6313],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1501,  0.5025, -0.2411],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.0192, -0.0141,  0.4895],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.7944,  1.1266, -0.7364]]])\n",
      "After concat vs cls_token: tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.1078,  0.6078, -0.7931],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6969, -1.3807,  1.0727],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6976, -1.2132,  0.7139],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.6209, -1.0919,  0.7523],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.0340,  1.2201, -0.1346],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6126, -0.9207, -1.0670],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5852,  1.7451,  0.6311],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.4041, -1.2397,  1.8388],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.9605,  0.1487, -0.1732],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8742,  0.8293,  0.5248],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1507, -0.0778, -0.1293],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8734, -2.1189, -0.0973],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.3704,  1.2938, -0.4054]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5379,  0.8660, -1.4143],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4281, -0.1816, -0.8599],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.7000, -1.1978, -0.8845],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0709, -0.0401, -0.3645],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8671, -0.7738,  0.4051],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5325,  0.7534,  0.0585],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.0775, -0.3009, -0.1811],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1016,  0.9733, -1.0202],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1264,  0.4393, -0.8988],\n",
      "         [ 0.0000,  1.0000,  0.0000, -3.9854,  0.8901, -0.6313],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1501,  0.5025, -0.2411],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.0192, -0.0141,  0.4895],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.7944,  1.1266, -0.7364]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "torch.Size([2, 14, 6])\n",
      "After add pos_embedding: tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.1078,  0.6078, -0.7931],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6969, -1.3807,  1.0727],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.6976, -1.2132,  0.7139],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.6209, -1.0919,  0.7523],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.0340,  1.2201, -0.1346],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.6126, -0.9207, -1.0670],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5852,  1.7451,  0.6311],\n",
      "         [ 0.0000,  0.0000,  1.0000, -0.4041, -1.2397,  1.8388],\n",
      "         [ 1.0000,  0.0000,  0.0000,  1.9605,  0.1487, -0.1732],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8742,  0.8293,  0.5248],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1507, -0.0778, -0.1293],\n",
      "         [ 1.0000,  0.0000,  0.0000,  0.8734, -2.1189, -0.0973],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.3704,  1.2938, -0.4054]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5379,  0.8660, -1.4143],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.4281, -0.1816, -0.8599],\n",
      "         [ 1.0000,  0.0000,  0.0000, -0.7000, -1.1978, -0.8845],\n",
      "         [ 0.0000,  1.0000,  0.0000, -1.0709, -0.0401, -0.3645],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.8671, -0.7738,  0.4051],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.5325,  0.7534,  0.0585],\n",
      "         [ 0.0000,  0.0000,  1.0000, -1.0775, -0.3009, -0.1811],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1016,  0.9733, -1.0202],\n",
      "         [ 0.0000,  1.0000,  0.0000,  0.1264,  0.4393, -0.8988],\n",
      "         [ 0.0000,  1.0000,  0.0000, -3.9854,  0.8901, -0.6313],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.1501,  0.5025, -0.2411],\n",
      "         [ 0.0000,  0.0000,  1.0000,  0.0192, -0.0141,  0.4895],\n",
      "         [ 0.0000,  1.0000,  0.0000, -0.7944,  1.1266, -0.7364]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 14, 6])\n",
      "torch.Size([2, 14, 6])\n",
      "torch.Size([2, 3])\n",
      "tensor([[ 0.9186, -0.7336, -0.1694],\n",
      "        [ 0.9062, -0.4520, -0.7090]], grad_fn=<AddmmBackward0>)\n",
      "1173\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class H39_63_ViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=3,\n",
    "        dim=6,\n",
    "        depth=3,\n",
    "        heads=2,\n",
    "        mlp_dim=12,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, 13 + 1, dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=nn.TransformerEncoderLayer(\n",
    "                d_model=dim,\n",
    "                nhead=heads,\n",
    "                dim_feedforward=mlp_dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,  # Đặt batch_first=True\n",
    "            ),\n",
    "            num_layers=depth,\n",
    "        )\n",
    "        self.head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):  # x shape (2, 13, 3) = (batch_size, num_patches, dim)\n",
    "        # print(f\"self.cls_token: {self.cls_token}\")\n",
    "        # print(f\"self.pos_embedding: {self.pos_embedding}\")\n",
    "        # print(f\"x: {x}\")\n",
    "        # print(x.shape)\n",
    "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        # print(cls_tokens.shape)\n",
    "\n",
    "        one_hot = F.one_hot(torch.argmax(x, dim=2), num_classes=x.size(2)).float()\n",
    "        # print(one_hot)\n",
    "        x = torch.cat((one_hot, x), dim=2)\n",
    "        # print(f\"After concat vs one_hot: {x}\")\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        # print(f\"After concat vs cls_token: {x}\")\n",
    "        # print(x.shape)\n",
    "        x += self.pos_embedding\n",
    "        # print(f\"After add pos_embedding: {x}\")\n",
    "        # print(x.shape)\n",
    "        x = self.transformer(x)\n",
    "        # print(x.shape)\n",
    "        x = self.head(x[:, 0])\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ví dụ sử dụng\n",
    "    model = ViT(num_classes=3, dim=6, depth=3, heads=2, mlp_dim=12)\n",
    "    x = torch.randn(2, 13, 3)  # Một batch gồm 2 ảnh\n",
    "    output = model(x)\n",
    "\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(num_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 3]) tensor([[ 1.4476,  0.7937, -0.6119],\n",
      "        [-0.0121,  0.1928,  1.8161],\n",
      "        [-0.7225, -0.0851,  0.9332],\n",
      "        [ 1.1289,  0.7718, -0.2430],\n",
      "        [-0.2996,  0.6422,  0.6020],\n",
      "        [ 1.2265,  1.2118, -0.7797],\n",
      "        [ 0.1727,  1.5401,  0.1851],\n",
      "        [-0.6264, -0.8372,  0.2559],\n",
      "        [-1.6641, -0.6122,  2.0225],\n",
      "        [ 0.1420,  0.7673,  0.2306],\n",
      "        [-1.2340, -0.7469,  0.7317],\n",
      "        [ 0.0363, -0.5170, -1.2705],\n",
      "        [-0.7391,  0.2611,  0.9240],\n",
      "        [-1.6722, -1.3749,  0.1121],\n",
      "        [ 3.5994, -1.2491,  1.4166],\n",
      "        [-0.5055,  0.1773, -0.3726],\n",
      "        [-0.8148, -0.0719, -0.1190],\n",
      "        [ 1.7486, -2.1217, -0.6415],\n",
      "        [-0.0672, -1.4461,  1.5898],\n",
      "        [ 0.3514, -1.6013, -0.4099],\n",
      "        [ 1.7133, -0.4120, -1.4850],\n",
      "        [-0.2850,  0.3422,  0.9327],\n",
      "        [ 1.8040,  0.2909, -0.3727],\n",
      "        [ 1.0165,  1.2955,  0.0141],\n",
      "        [ 0.8261, -0.5779, -0.0935],\n",
      "        [ 0.4408, -0.2276,  0.6525]])\n",
      "torch.Size([2, 13, 3]) tensor([[[ 1.4476,  0.7937, -0.6119],\n",
      "         [-0.0121,  0.1928,  1.8161],\n",
      "         [-0.7225, -0.0851,  0.9332],\n",
      "         [ 1.1289,  0.7718, -0.2430],\n",
      "         [-0.2996,  0.6422,  0.6020],\n",
      "         [ 1.2265,  1.2118, -0.7797],\n",
      "         [ 0.1727,  1.5401,  0.1851],\n",
      "         [-0.6264, -0.8372,  0.2559],\n",
      "         [-1.6641, -0.6122,  2.0225],\n",
      "         [ 0.1420,  0.7673,  0.2306],\n",
      "         [-1.2340, -0.7469,  0.7317],\n",
      "         [ 0.0363, -0.5170, -1.2705],\n",
      "         [-0.7391,  0.2611,  0.9240]],\n",
      "\n",
      "        [[-1.6722, -1.3749,  0.1121],\n",
      "         [ 3.5994, -1.2491,  1.4166],\n",
      "         [-0.5055,  0.1773, -0.3726],\n",
      "         [-0.8148, -0.0719, -0.1190],\n",
      "         [ 1.7486, -2.1217, -0.6415],\n",
      "         [-0.0672, -1.4461,  1.5898],\n",
      "         [ 0.3514, -1.6013, -0.4099],\n",
      "         [ 1.7133, -0.4120, -1.4850],\n",
      "         [-0.2850,  0.3422,  0.9327],\n",
      "         [ 1.8040,  0.2909, -0.3727],\n",
      "         [ 1.0165,  1.2955,  0.0141],\n",
      "         [ 0.8261, -0.5779, -0.0935],\n",
      "         [ 0.4408, -0.2276,  0.6525]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(26, 3)\n",
    "print(x.shape, x)\n",
    "y = x.view(-1, 13, 3)\n",
    "print(y.shape, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_work#311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
